"""
This type stub file was generated by pyright.
"""

"""
Utilities for working with the local dataset cache.
This file is adapted from `AllenNLP <https://github.com/allenai/allennlp>`_.
and `huggingface <https://github.com/huggingface>`_.
"""
torch_cache_home = ...
default_cache_path = ...
PYTORCH_FAIRSEQ_CACHE = ...
CONFIG_NAME = ...
WEIGHTS_NAME = ...
logger = ...
def load_archive_file(archive_file): # -> str | None:
    ...

def url_to_filename(url, etag=...): # -> str:
    """
    Convert `url` into a hashed filename in a repeatable way.
    If `etag` is specified, append its hash to the URL's, delimited
    by a period.
    """
    ...

def filename_to_url(filename, cache_dir=...): # -> tuple[Any, Any]:
    """
    Return the url and etag (which may be ``None``) stored for `filename`.
    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.
    """
    ...

def cached_path_from_pm(url_or_filename): # -> str | None:
    """
    Tries to cache the specified URL using PathManager class.
    Returns the cached path if success otherwise failure.
    """
    ...

def cached_path(url_or_filename, cache_dir=...): # -> str:
    """
    Given something that might be a URL (or might be a local path),
    determine which. If it's a URL, download the file and cache it, and
    return the path to the cached file. If it's already a local path,
    make sure the file exists and then return the path.
    """
    ...

def split_s3_path(url): # -> tuple[Any, Any]:
    """Split a full s3 path into the bucket name and path."""
    ...

def s3_request(func): # -> _Wrapped[..., Any, ..., Any]:
    """
    Wrapper function for s3 requests in order to create more helpful error
    messages.
    """
    ...

@s3_request
def s3_etag(url):
    """Check ETag on S3 object."""
    ...

@s3_request
def s3_get(url, temp_file): # -> None:
    """Pull a file directly from S3."""
    ...

def request_wrap_timeout(func, url):
    ...

def http_get(url, temp_file): # -> None:
    ...

def get_from_cache(url, cache_dir=...): # -> str:
    """
    Given a URL, look for the corresponding dataset in the local cache.
    If it's not there, download it. Then return the path to the cached file.
    """
    ...

def read_set_from_file(filename): # -> set[Any]:
    """
    Extract a de-duped collection (set) of text from a file.
    Expected file format is one item per line.
    """
    ...

def get_file_extension(path, dot=..., lower=...):
    ...

