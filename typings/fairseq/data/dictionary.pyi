"""
This type stub file was generated by pyright.
"""

import torch

class Dictionary:
    """A mapping from symbols to consecutive integers"""
    def __init__(self, *, bos=..., pad=..., eos=..., unk=..., extra_special_symbols=...) -> None:
        ...
    
    def __eq__(self, other) -> bool:
        ...
    
    def __getitem__(self, idx): # -> str:
        ...
    
    def get_count(self, idx):
        ...
    
    def __len__(self): # -> int:
        """Returns the number of symbols in the dictionary"""
        ...
    
    def __contains__(self, sym): # -> bool:
        ...
    
    def index(self, sym): # -> int:
        """Returns the index of the specified symbol"""
        ...
    
    def string(self, tensor, bpe_symbol=..., escape_unk=..., extra_symbols_to_ignore=..., unk_string=..., include_eos=..., separator=...): # -> str:
        """Helper for converting a tensor of token indices to a string.

        Can optionally remove BPE symbols or escape <unk> words.
        """
        ...
    
    def unk_string(self, escape=...): # -> str:
        """Return unknown string, optionally escaped as: <<unk>>"""
        ...
    
    def add_symbol(self, word, n=..., overwrite=...): # -> int:
        """Adds a word to the dictionary"""
        ...
    
    def update(self, new_dict): # -> None:
        """Updates counts from new dictionary."""
        ...
    
    def finalize(self, threshold=..., nwords=..., padding_factor=...): # -> None:
        """Sort symbols by frequency in descending order, ignoring special ones.

        Args:
            - threshold defines the minimum word count
            - nwords defines the total number of words in the final dictionary,
                including special symbols
            - padding_factor can be used to pad the dictionary size to be a
                multiple of 8, which is important on some hardware (e.g., Nvidia
                Tensor Cores).
        """
        ...
    
    def pad_to_multiple_(self, padding_factor): # -> None:
        """Pad Dictionary size to be a multiple of *padding_factor*."""
        ...
    
    def bos(self): # -> int:
        """Helper to get index of beginning-of-sentence symbol"""
        ...
    
    def pad(self): # -> int:
        """Helper to get index of pad symbol"""
        ...
    
    def eos(self): # -> int:
        """Helper to get index of end-of-sentence symbol"""
        ...
    
    def unk(self): # -> int:
        """Helper to get index of unk symbol"""
        ...
    
    @classmethod
    def load(cls, f): # -> Self:
        """Loads the dictionary from a text file with the format:

        ```
        <symbol0> <count0>
        <symbol1> <count1>
        ...
        ```
        """
        ...
    
    def add_from_file(self, f): # -> None:
        """
        Loads a pre-existing dictionary from a text file and adds its symbols
        to this instance.
        """
        ...
    
    def save(self, f): # -> None:
        """Stores dictionary into a text file"""
        ...
    
    def dummy_sentence(self, length): # -> Tensor:
        ...
    
    def encode_line(self, line, line_tokenizer=..., add_if_not_exist=..., consumer=..., append_eos=..., reverse_order=...) -> torch.IntTensor:
        ...
    
    @staticmethod
    def add_file_to_dictionary(filename, dict, tokenize, num_workers): # -> None:
        ...
    


class TruncatedDictionary:
    def __init__(self, wrapped_dict, length) -> None:
        ...
    
    def __len__(self): # -> int:
        ...
    
    def __getitem__(self, i):
        ...
    


