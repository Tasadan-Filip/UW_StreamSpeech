"""
This type stub file was generated by pyright.
"""

import torch

class WordNoising:
    """Generate a noisy version of a sentence, without changing words themselves."""
    def __init__(self, dictionary, bpe_cont_marker=..., bpe_end_marker=...) -> None:
        ...
    
    def noising(self, x, lengths, noising_prob=...):
        ...
    


class WordDropout(WordNoising):
    """Randomly drop input words. If not passing blank_idx (default is None),
    then dropped words will be removed. Otherwise, it will be replaced by the
    blank_idx."""
    def __init__(self, dictionary, default_dropout_prob=..., bpe_cont_marker=..., bpe_end_marker=...) -> None:
        ...
    
    def noising(self, x, lengths, dropout_prob=..., blank_idx=...): # -> tuple[Any, Any] | tuple[Tensor, LongTensor]:
        ...
    


class WordShuffle(WordNoising):
    """Shuffle words by no more than k positions."""
    def __init__(self, dictionary, default_max_shuffle_distance=..., bpe_cont_marker=..., bpe_end_marker=...) -> None:
        ...
    
    def noising(self, x, lengths, max_shuffle_distance=...): # -> tuple[Any, Any]:
        ...
    


class UnsupervisedMTNoising(WordNoising):
    """
    Implements the default configuration for noising in UnsupervisedMT
    (github.com/facebookresearch/UnsupervisedMT)
    """
    def __init__(self, dictionary, max_word_shuffle_distance, word_dropout_prob, word_blanking_prob, bpe_cont_marker=..., bpe_end_marker=...) -> None:
        ...
    
    def noising(self, x, lengths): # -> Tensor:
        ...
    


class NoisingDataset(torch.utils.data.Dataset):
    def __init__(self, src_dataset, src_dict, seed, noiser=..., noising_class=..., **kwargs) -> None:
        """
        Wrap a :class:`~torch.utils.data.Dataset` and apply noise to the
        samples based on the supplied noising configuration.

        Args:
            src_dataset (~torch.utils.data.Dataset): dataset to wrap.
                to build self.src_dataset --
                a LanguagePairDataset with src dataset as the source dataset and
                None as the target dataset. Should NOT have padding so that
                src_lengths are accurately calculated by language_pair_dataset
                collate function.
                We use language_pair_dataset here to encapsulate the tgt_dataset
                so we can re-use the LanguagePairDataset collater to format the
                batches in the structure that SequenceGenerator expects.
            src_dict (~fairseq.data.Dictionary): source dictionary
            seed (int): seed to use when generating random noise
            noiser (WordNoising): a pre-initialized :class:`WordNoising`
                instance. If this is None, a new instance will be created using
                *noising_class* and *kwargs*.
            noising_class (class, optional): class to use to initialize a
                default :class:`WordNoising` instance.
            kwargs (dict, optional): arguments to initialize the default
                :class:`WordNoising` instance given by *noiser*.
        """
        ...
    
    def __getitem__(self, index): # -> Tensor:
        """
        Returns a single noisy sample. Multiple samples are fed to the collater
        create a noising dataset batch.
        """
        ...
    
    def __len__(self): # -> int:
        """
        The length of the noising dataset is the length of src.
        """
        ...
    
    @property
    def supports_prefetch(self):
        ...
    
    def prefetch(self, indices): # -> None:
        ...
    


