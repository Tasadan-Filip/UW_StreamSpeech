"""
This type stub file was generated by pyright.
"""

from pathlib import Path
from typing import Dict, Optional

def get_config_from_yaml(yaml_path: Path): # -> Any:
    ...

class S2TDataConfig:
    """Wrapper class for data config YAML"""
    def __init__(self, yaml_path: Path) -> None:
        ...
    
    @property
    def vocab_filename(self): # -> Any:
        """fairseq vocabulary file under data root"""
        ...
    
    @property
    def speaker_set_filename(self): # -> Any:
        """speaker set file under data root"""
        ...
    
    @property
    def shuffle(self) -> bool:
        """Shuffle dataset samples before batching"""
        ...
    
    @property
    def pre_tokenizer(self) -> Dict:
        """Pre-tokenizer to apply before subword tokenization. Returning
        a dictionary with `tokenizer` providing the tokenizer name and
        the other items providing the tokenizer-specific arguments.
        Tokenizers are defined in `fairseq.data.encoders.*`"""
        ...
    
    @property
    def bpe_tokenizer(self) -> Dict:
        """Subword tokenizer to apply after pre-tokenization. Returning
        a dictionary with `bpe` providing the tokenizer name and
        the other items providing the tokenizer-specific arguments.
        Tokenizers are defined in `fairseq.data.encoders.*`"""
        ...
    
    @property
    def prepend_tgt_lang_tag(self) -> bool:
        """Prepend target lang ID token as the target BOS (e.g. for to-many
        multilingual setting). During inference, this requires `--prefix-size 1`
        to force BOS to be lang ID token."""
        ...
    
    @property
    def prepend_bos_and_append_tgt_lang_tag(self) -> bool:
        """Prepend BOS and append target lang ID token to the target (e.g. mBART with language token pretraining)."""
        ...
    
    @property
    def input_feat_per_channel(self): # -> Any:
        """The dimension of input features (per audio channel)"""
        ...
    
    @property
    def input_channels(self): # -> Any:
        """The number of channels in the input audio"""
        ...
    
    @property
    def sample_rate(self): # -> Any:
        ...
    
    @property
    def sampling_alpha(self): # -> Any:
        """Hyper-parameter alpha = 1/T for temperature-based resampling.
        (alpha = 1 for no resampling)"""
        ...
    
    @property
    def use_audio_input(self): # -> Any:
        """Needed by the dataset loader to see if the model requires
        raw audio as inputs."""
        ...
    
    def standardize_audio(self) -> bool:
        ...
    
    @property
    def use_sample_rate(self): # -> Any:
        """Needed by the dataset loader to see if the model requires
        raw audio with specific sample rate as inputs."""
        ...
    
    @property
    def audio_root(self): # -> Any:
        """Audio paths in the manifest TSV can be relative and this provides
        the root path. Set this to empty string when using absolute paths."""
        ...
    
    def get_feature_transforms(self, split, is_train): # -> Any:
        """Split-specific feature transforms. Allowing train set
        wildcard `_train`, evaluation set wildcard `_eval` and general
        wildcard `*` for matching."""
        ...
    
    @property
    def global_cmvn_stats_npz(self) -> Optional[str]:
        ...
    
    @property
    def vocoder(self) -> Dict[str, str]:
        ...
    
    @property
    def hub(self) -> Dict[str, str]:
        ...
    


class S2SDataConfig(S2TDataConfig):
    """Wrapper class for data config YAML"""
    @property
    def vocab_filename(self): # -> Any:
        """fairseq vocabulary file under data root"""
        ...
    
    @property
    def pre_tokenizer(self) -> Dict:
        ...
    
    @property
    def bpe_tokenizer(self) -> Dict:
        ...
    
    @property
    def input_transformed_channels(self): # -> Any:
        """The number of channels in the audio after feature transforms"""
        ...
    
    @property
    def output_sample_rate(self): # -> Any:
        """The audio sample rate of output target speech"""
        ...
    
    @property
    def target_speaker_embed(self): # -> Any:
        """Target speaker embedding file (one line per target audio sample)"""
        ...
    
    @property
    def prepend_tgt_lang_tag_as_bos(self) -> bool:
        """Prepend target lang ID token as the target BOS."""
        ...
    


class MultitaskConfig:
    """Wrapper class for data config YAML"""
    def __init__(self, yaml_path: Path) -> None:
        ...
    
    def get_all_tasks(self): # -> dict[Any, Any]:
        ...
    
    def get_single_task(self, name):
        ...
    


class SingleTaskConfig:
    def __init__(self, name, config) -> None:
        ...
    
    @property
    def data(self):
        ...
    
    @property
    def decoder_type(self):
        ...
    
    @property
    def decoder_args(self): # -> Namespace:
        """Decoder arch related args"""
        ...
    
    @property
    def criterion_cfg(self): # -> type[CtcCriterionConfig] | type[LabelSmoothedCrossEntropyCriterionConfig]:
        """cfg for the multitask criterion"""
        ...
    
    @property
    def input_from(self): # -> Literal['decoder', 'encoder']:
        """Condition on encoder/decoder of the main model"""
        ...
    
    @property
    def input_layer(self):
        ...
    
    @property
    def loss_weight_schedule(self): # -> Literal['decay', 'fixed']:
        ...
    
    def get_loss_weight(self, num_updates):
        ...
    


