"""
This type stub file was generated by pyright.
"""

from fairseq.data import FairseqDataset

logger = ...
def collate(samples, pad_idx, eos_idx, left_pad_source=..., left_pad_target=..., input_feeding=..., pad_to_length=..., pad_to_multiple=...): # -> dict[Any, Any] | dict[str, Number | Tensor | Any | dict[str, Any] | None]:
    ...

class LanguagePairDataset(FairseqDataset):
    """
    A pair of torch.utils.data.Datasets.

    Args:
        src (torch.utils.data.Dataset): source dataset to wrap
        src_sizes (List[int]): source sentence lengths
        src_dict (~fairseq.data.Dictionary): source vocabulary
        tgt (torch.utils.data.Dataset, optional): target dataset to wrap
        tgt_sizes (List[int], optional): target sentence lengths
        tgt_dict (~fairseq.data.Dictionary, optional): target vocabulary
        left_pad_source (bool, optional): pad source tensors on the left side
            (default: True).
        left_pad_target (bool, optional): pad target tensors on the left side
            (default: False).
        shuffle (bool, optional): shuffle dataset elements before batching
            (default: True).
        input_feeding (bool, optional): create a shifted version of the targets
            to be passed into the model for teacher forcing (default: True).
        remove_eos_from_source (bool, optional): if set, removes eos from end
            of source if it's present (default: False).
        append_eos_to_target (bool, optional): if set, appends eos to end of
            target if it's absent (default: False).
        align_dataset (torch.utils.data.Dataset, optional): dataset
            containing alignments.
        constraints (Tensor, optional): 2d tensor with a concatenated, zero-
            delimited list of constraints for each sentence.
        append_bos (bool, optional): if set, appends bos to the beginning of
            source/target sentence.
        num_buckets (int, optional): if set to a value greater than 0, then
            batches will be bucketed into the given number of batch shapes.
        src_lang_id (int, optional): source language ID, if set, the collated batch
            will contain a field 'src_lang_id' in 'net_input' which indicates the
            source language of the samples.
        tgt_lang_id (int, optional): target language ID, if set, the collated batch
            will contain a field 'tgt_lang_id' which indicates the target language
             of the samples.
    """
    def __init__(self, src, src_sizes, src_dict, tgt=..., tgt_sizes=..., tgt_dict=..., left_pad_source=..., left_pad_target=..., shuffle=..., input_feeding=..., remove_eos_from_source=..., append_eos_to_target=..., align_dataset=..., constraints=..., append_bos=..., eos=..., num_buckets=..., src_lang_id=..., tgt_lang_id=..., pad_to_multiple=...) -> None:
        ...
    
    def get_batch_shapes(self): # -> list[tuple[None, Any]] | None:
        ...
    
    def __getitem__(self, index): # -> dict[str, Any | Tensor | None]:
        ...
    
    def __len__(self): # -> int:
        ...
    
    def collater(self, samples, pad_to_length=...): # -> dict[Any, Any] | dict[str, Number | Tensor | Any | dict[str, Any] | None]:
        """Merge a list of samples to form a mini-batch.

        Args:
            samples (List[dict]): samples to collate
            pad_to_length (dict, optional): a dictionary of
                {'source': source_pad_to_length, 'target': target_pad_to_length}
                to indicate the max length to pad to in source and target respectively.

        Returns:
            dict: a mini-batch with the following keys:

                - `id` (LongTensor): example IDs in the original input order
                - `ntokens` (int): total number of tokens in the batch
                - `net_input` (dict): the input to the Model, containing keys:

                  - `src_tokens` (LongTensor): a padded 2D Tensor of tokens in
                    the source sentence of shape `(bsz, src_len)`. Padding will
                    appear on the left if *left_pad_source* is ``True``.
                  - `src_lengths` (LongTensor): 1D Tensor of the unpadded
                    lengths of each source sentence of shape `(bsz)`
                  - `prev_output_tokens` (LongTensor): a padded 2D Tensor of
                    tokens in the target sentence, shifted right by one
                    position for teacher forcing, of shape `(bsz, tgt_len)`.
                    This key will not be present if *input_feeding* is
                    ``False``.  Padding will appear on the left if
                    *left_pad_target* is ``True``.
                  - `src_lang_id` (LongTensor): a long Tensor which contains source
                    language IDs of each sample in the batch

                - `target` (LongTensor): a padded 2D Tensor of tokens in the
                  target sentence of shape `(bsz, tgt_len)`. Padding will appear
                  on the left if *left_pad_target* is ``True``.
                - `tgt_lang_id` (LongTensor): a long Tensor which contains target language
                   IDs of each sample in the batch
        """
        ...
    
    def num_tokens(self, index):
        """Return the number of tokens in a sample. This value is used to
        enforce ``--max-tokens`` during batching."""
        ...
    
    def num_tokens_vec(self, indices): # -> NDArray[Any] | ndarray[Any, dtype[Any]]:
        """Return the number of tokens for a set of positions defined by indices.
        This value is used to enforce ``--max-tokens`` during batching."""
        ...
    
    def size(self, index): # -> tuple[ndarray[Any, dtype[Any]], ndarray[Any, dtype[Any]] | Literal[0]]:
        """Return an example's size as a float or tuple. This value is used when
        filtering a dataset with ``--max-positions``."""
        ...
    
    def ordered_indices(self): # -> ndarray[Any, dtype[signedinteger[_64Bit]]]:
        """Return an ordered list of indices. Batches will be constructed based
        on this order."""
        ...
    
    @property
    def supports_prefetch(self): # -> Any | bool:
        ...
    
    def prefetch(self, indices): # -> None:
        ...
    
    def filter_indices_by_size(self, indices, max_sizes): # -> tuple[Any, list[Any]] | tuple[Any, Any]:
        """Filter a list of sample indices. Remove those that are longer
            than specified in max_sizes.

        Args:
            indices (np.array): original array of sample indices
            max_sizes (int or list[int] or tuple[int]): max sample size,
                can be defined separately for src and tgt (then list or tuple)

        Returns:
            np.array: filtered sample array
            list: list of removed indices
        """
        ...
    


