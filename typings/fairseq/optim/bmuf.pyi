"""
This type stub file was generated by pyright.
"""

from fairseq.dataclass.configs import FairseqBMUFConfig
from fairseq.optim.fairseq_optimizer import FairseqOptimizer

class FairseqBMUF(FairseqOptimizer):
    """
    Implements incremental block distributed data parallelism similar to
    https://ieeexplore.ieee.org/document/7472805

    Paper title: Scalable training of deep learning machines by incremental
    block training with intra-block parallel optimization and blockwise
    model-update filtering
    """
    def __init__(self, cfg: FairseqBMUFConfig, optimizer) -> None:
        ...
    
    @staticmethod
    def add_args(parser): # -> None:
        """Add optimizer-specific arguments to the parser."""
        ...
    
    @property
    def optimizer(self):
        ...
    
    @property
    def optimizer_config(self):
        ...
    
    def get_lr(self):
        ...
    
    def set_lr(self, lr): # -> None:
        ...
    
    def state_dict(self):
        ...
    
    def load_state_dict(self, state_dict, optimizer_overrides=...): # -> None:
        ...
    
    def multiply_grads(self, c): # -> None:
        """Multiplies grads by a constant *c*."""
        ...
    
    def clip_grad_norm(self, max_norm, aggregate_norm_fn=...):
        """Clips gradient norm."""
        ...
    
    def average_params(self): # -> None:
        ...
    
    def step(self, closure=...): # -> None:
        """Performs a single optimization step."""
        ...
    
    def zero_grad(self): # -> None:
        """Clears the gradients of all optimized parameters."""
        ...
    
    def get_num_updates(self): # -> int:
        """Get the number of parameters updates."""
        ...
    
    def set_num_updates(self, num_updates): # -> None:
        """Set the number of parameters updates."""
        ...
    


