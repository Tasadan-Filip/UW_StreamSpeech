"""
This type stub file was generated by pyright.
"""

import argparse
import contextlib
import torch
from typing import Callable, Dict, List, Optional, TYPE_CHECKING
from torch import Tensor
from fairseq.modules.multihead_attention import MultiheadAttention

if TYPE_CHECKING:
    ...
multi_tensor_l2norm_available = ...
logger = ...
MANIFOLD_PATH_SEP = ...
class FileContentsAction(argparse.Action):
    def __init__(self, option_strings, dest, nargs=..., **kwargs) -> None:
        ...
    
    def __call__(self, parser, namespace, values, option_string=...): # -> None:
        ...
    


def split_paths(paths: str, separator=...) -> List[str]:
    ...

def load_ensemble_for_inference(filenames, task, model_arg_overrides=...): # -> tuple[list[Any], DictConfig | Any | None]:
    ...

def apply_to_sample(f, sample): # -> dict[Any, Any] | OrderedDict[Any, Any | dict[Any, Any | dict[Any, Any] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | dict[Any, Any | dict[Any, Any] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]:
    ...

def move_to_cuda(sample, device=...): # -> dict[Any, Any] | OrderedDict[Any, Any | dict[Any, Any | dict[Any, Any] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | dict[Any, Any | dict[Any, Any] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]:
    ...

def move_to_cpu(sample): # -> dict[Any, Any] | OrderedDict[Any, Any | dict[Any, Any | dict[Any, Any] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | dict[Any, Any | dict[Any, Any] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]:
    ...

def move_to_tpu(sample): # -> dict[Any, Any] | OrderedDict[Any, Any | dict[Any, Any | dict[Any, Any] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | dict[Any, Any | dict[Any, Any] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | list[Any | dict[Any, Any] | list[Any] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]] | tuple[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]], ...] | set[Any | dict[Any, Any] | list[Any] | tuple[Any, ...] | set[Any]]:
    ...

def get_incremental_state(module: MultiheadAttention, incremental_state: Optional[Dict[str, Dict[str, Optional[Tensor]]]], key: str) -> Optional[Dict[str, Optional[Tensor]]]:
    """Helper for getting incremental state for an nn.Module."""
    ...

def set_incremental_state(module: MultiheadAttention, incremental_state: Optional[Dict[str, Dict[str, Optional[Tensor]]]], key: str, value: Dict[str, Optional[Tensor]]) -> Optional[Dict[str, Dict[str, Optional[Tensor]]]]:
    """Helper for setting incremental state for an nn.Module."""
    ...

def load_align_dict(replace_unk): # -> dict[Any, Any] | None:
    ...

def print_embed_overlap(embed_dict, vocab_dict): # -> None:
    ...

def parse_embedding(embed_path): # -> dict[Any, Any]:
    """Parse embedding text file into a dictionary of word and embedding tensors.

    The first line can have vocabulary size and dimension. The following lines
    should contain word and embedding separated by spaces.

    Example:
        2 5
        the -0.0230 -0.0264  0.0287  0.0171  0.1403
        at -0.0395 -0.1286  0.0275  0.0254 -0.0932
    """
    ...

def load_embedding(embed_dict, vocab, embedding):
    ...

def replace_unk(hypo_str, src_str, alignment, align_dict, unk): # -> str:
    ...

def post_process_prediction(hypo_tokens, src_str, alignment, align_dict, tgt_dict, remove_bpe=..., extra_symbols_to_ignore=...): # -> tuple[Any, str | Any, Any]:
    ...

def make_positions(tensor, padding_idx: int, onnx_trace: bool = ...):
    """Replace non-padding symbols with their position numbers.

    Position numbers begin at padding_idx+1. Padding symbols are ignored.
    """
    ...

def strip_pad(tensor, pad):
    ...

def buffered_arange(max): # -> Tensor | Any:
    ...

def convert_padding_direction(src_tokens, padding_idx, right_to_left: bool = ..., left_to_right: bool = ...):
    ...

def item(tensor):
    ...

def multi_tensor_total_norm(grads, chunk_size=...) -> torch.Tensor:
    ...

@torch.no_grad()
def clip_grad_norm_(params, max_norm, aggregate_norm_fn=...) -> torch.Tensor:
    ...

def fill_with_neg_inf(t):
    """FP16-compatible function that fills a tensor with -inf."""
    ...

def resolve_max_positions(*args): # -> float | int | tuple[float | int, ...] | dict[Any, Any] | tuple[Any | None, ...] | None:
    """Resolve max position constraints from multiple sources."""
    ...

def import_user_module(args): # -> None:
    ...

def softmax(x, dim: int, onnx_trace: bool = ...): # -> Tensor:
    ...

def log_softmax(x, dim: int, onnx_trace: bool = ...): # -> Tensor:
    ...

def get_perplexity(loss, round=..., base=...): # -> float:
    ...

def deprecation_warning(message, stacklevel=...): # -> None:
    ...

def relu_squared(x: torch.Tensor): # -> Tensor:
    ...

def get_activation_fn(activation: str) -> Callable:
    """Returns the activation function corresponding to `activation`"""
    ...

def get_available_activation_fns() -> List:
    ...

@contextlib.contextmanager
def model_eval(model): # -> Generator[None, Any, None]:
    ...

def has_parameters(module): # -> bool:
    ...

def get_rng_state(): # -> dict[str, Tensor]:
    ...

def set_rng_state(state): # -> None:
    ...

class set_torch_seed:
    def __init__(self, seed) -> None:
        ...
    
    def __enter__(self): # -> Self:
        ...
    
    def __exit__(self, *exc): # -> None:
        ...
    


def parse_alignment(line): # -> IntTensor:
    """
    Parses a single line from the alingment file.

    Args:
        line (str): String containing the alignment of the format:
            <src_idx_1>-<tgt_idx_1> <src_idx_2>-<tgt_idx_2> ..
            <src_idx_m>-<tgt_idx_m>. All indices are 0 indexed.

    Returns:
        torch.IntTensor: packed alignments of shape (2 * m).
    """
    ...

def get_token_to_word_mapping(tokens, exclude_list): # -> dict[int, int]:
    ...

def extract_hard_alignment(attn, src_sent, tgt_sent, pad, eos): # -> list[Any]:
    ...

def extract_soft_alignment(attn, src_sent, tgt_sent, pad, eos): # -> list[list[str]]:
    ...

def new_arange(x, *size): # -> Tensor:
    """
    Return a Tensor of `size` filled with a range function on the device of x.
    If size is empty, using the size of the variable x.
    """
    ...

def get_tpu_device():
    ...

def tpu_data_loader(itr): # -> CountingIterator:
    ...

def is_xla_tensor(tensor): # -> Literal[False]:
    ...

def index_put(tensor, indices, value): # -> Tensor:
    ...

def xla_device_to_cpu(dat):
    ...

class CudaEnvironment:
    def __init__(self) -> None:
        ...
    
    @staticmethod
    def pretty_print_cuda_env_list(cuda_env_list): # -> None:
        """
        Given a list of CudaEnviorments, pretty print them
        """
        ...
    


def csv_str_list(x):
    ...

def eval_str_list(x, type=...): # -> list[float] | None:
    ...

def eval_str_dict(x, type=...): # -> Any | None:
    ...

def eval_bool(x, default=...): # -> bool:
    ...

def reset_logging(): # -> None:
    ...

def safe_getattr(obj, k, default=...): # -> Any | None:
    """Returns obj[k] if it exists and is not None, otherwise returns default."""
    ...

def safe_hasattr(obj, k): # -> bool:
    """Returns True if the given key exists and is not None."""
    ...

def hotreload_function(name=...): # -> Callable[..., Callable[..., object]]:
    """
    Decorator to function to enable hot-reload for debugging.
    It allows you to debug a function without having reloading all heavy models, dataset loading and
        preprocessing, allow faster debugging.
    If you want to change model or dataset loading, consider relaunching your code
    -----------------------------------
    This will run the decorated function func:
        if func run successful:
            It will pause, allow user to edit code, and prompt user to:
                Press enter to re-run the function with updated code
                Type "done" to finish the function, return output
                Type "disable" to stop pausing this function and let code continue without pause
                Ctril + C to terminal
        if func raise error:
            it will prompt user to
                1. Edit code, and press enter to retry
                2. Ctrl + C to terminate
                3. Type "raise" to raise that exception
    * Requirements:
        0. Fairseq was installed with `pip install --editable .`
        1. pip install jurigged[develoop]
        2. set environment HOTRELOAD_PAUSE=1 CUDA_LAUNCH_BLOCKING=1
        3. Run on only 1 GPU (no distributed)
    * How to use:
        1. in python, import and decorate the top-level function to be re-run after code edits:
            ```python
            from fairseq.utils import hotreload_function
            ....
            @hotreload_function("train_step")
            def train_step(self, sample ....):
                ....
            ....
            ```
        2. in bash run scripts:
            ```bash
            watch_dir=<home>/fairseq-py/fairseq/tasks # directory to watch for file changes
            export CUDA_VISIBLE_DEVICES=0 # single-gpu
            HOTRELOAD_PAUSE=1 CUDA_LAUNCH_BLOCKING=1 python -m jurigged -w ${watch_dir} --poll 2 -v train.py ......
            ```
    * NOTE:
        1. -w ${watch_dir} specify all the files to be watched for changes
            once functions, class, ... code are changed, all instances in the process will get updated (hot-reload)
    * Limitation:
        * Currently distributed debugging not working
        * Need to launch train.py locally (cannot submit jobs)
    """
    ...

