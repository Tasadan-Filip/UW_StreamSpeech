"""
This type stub file was generated by pyright.
"""

from typing import List
from flashlight.lib.text.decoder import LM, LMState

"""
Flashlight decoders.
"""
class W2lDecoder:
    def __init__(self, args, tgt_dict) -> None:
        ...
    
    def generate(self, models, sample, **unused):
        """Generate a batch of inferences."""
        ...
    
    def get_emissions(self, models, encoder_input):
        """Run encoder and normalize emissions"""
        ...
    
    def get_tokens(self, idxs): # -> LongTensor:
        """Normalize tokens by handling CTC blank, ASG replabels, etc."""
        ...
    


class W2lViterbiDecoder(W2lDecoder):
    def __init__(self, args, tgt_dict) -> None:
        ...
    
    def decode(self, emissions): # -> list[list[dict[str, LongTensor | int]]]:
        ...
    


class W2lKenLMDecoder(W2lDecoder):
    def __init__(self, args, tgt_dict) -> None:
        ...
    
    def get_timesteps(self, token_idxs: List[int]) -> List[int]:
        """Returns frame numbers corresponding to every non-blank token.

        Parameters
        ----------
        token_idxs : List[int]
            IDs of decoded tokens.

        Returns
        -------
        List[int]
            Frame numbers corresponding to every non-blank token.
        """
        ...
    
    def decode(self, emissions): # -> list[Any]:
        ...
    


FairseqLMState = ...
class FairseqLM(LM):
    def __init__(self, dictionary, model) -> None:
        ...
    
    def start(self, start_with_nothing): # -> object:
        ...
    
    def score(self, state: LMState, token_index: int, no_cache: bool = ...): # -> tuple[Any, float | Any]:
        """
        Evaluate language model based on the current lm state and new word
        Parameters:
        -----------
        state: current lm state
        token_index: index of the word
                     (can be lexicon index then you should store inside LM the
                      mapping between indices of lexicon and lm, or lm index of a word)

        Returns:
        --------
        (LMState, float): pair of (new state, score for the current word)
        """
        ...
    
    def finish(self, state: LMState): # -> tuple[Any, float | Any]:
        """
        Evaluate eos for language model based on the current lm state

        Returns:
        --------
        (LMState, float): pair of (new state, score for the current word)
        """
        ...
    
    def empty_cache(self): # -> None:
        ...
    


class W2lFairseqLMDecoder(W2lDecoder):
    def __init__(self, args, tgt_dict) -> None:
        ...
    
    def decode(self, emissions): # -> list[Any]:
        ...
    


