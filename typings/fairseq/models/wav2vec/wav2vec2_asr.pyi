"""
This type stub file was generated by pyright.
"""

from dataclasses import dataclass
from typing import Any, Optional
from fairseq.dataclass import FairseqDataclass
from fairseq.models import BaseFairseqModel, FairseqEncoder, FairseqEncoderDecoderModel, FairseqIncrementalDecoder, register_model
from fairseq.models.wav2vec.wav2vec2 import MASKING_DISTRIBUTION_CHOICES
from fairseq.tasks import FairseqTask

logger = ...
@dataclass
class Wav2Vec2AsrConfig(FairseqDataclass):
    w2v_path: str = ...
    no_pretrained_weights: bool = ...
    dropout_input: float = ...
    final_dropout: float = ...
    dropout: float = ...
    attention_dropout: float = ...
    activation_dropout: float = ...
    conv_feature_layers: Optional[str] = ...
    encoder_embed_dim: Optional[int] = ...
    apply_mask: bool = ...
    mask_length: int = ...
    mask_prob: float = ...
    mask_selection: MASKING_DISTRIBUTION_CHOICES = ...
    mask_other: float = ...
    no_mask_overlap: bool = ...
    mask_min_space: Optional[int] = ...
    require_same_masks: bool = ...
    mask_dropout: float = ...
    mask_channel_length: int = ...
    mask_channel_prob: float = ...
    mask_channel_selection: MASKING_DISTRIBUTION_CHOICES = ...
    mask_channel_other: float = ...
    no_mask_channel_overlap: bool = ...
    freeze_finetune_updates: int = ...
    feature_grad_mult: float = ...
    layerdrop: float = ...
    mask_channel_min_space: Optional[int] = ...
    mask_channel_before: bool = ...
    normalize: bool = ...
    data: str = ...
    w2v_args: Any = ...
    offload_activations: bool = ...
    min_params_to_wrap: int = ...
    checkpoint_activations: bool = ...
    ddp_backend: str = ...


@dataclass
class Wav2Vec2CtcConfig(Wav2Vec2AsrConfig):
    blank_weight: float = ...
    blank_mode: str = ...


@register_model("wav2vec_ctc", dataclass=Wav2Vec2CtcConfig)
class Wav2VecCtc(BaseFairseqModel):
    def __init__(self, cfg: Wav2Vec2CtcConfig, w2v_encoder: BaseFairseqModel) -> None:
        ...
    
    def upgrade_state_dict_named(self, state_dict, name):
        ...
    
    @classmethod
    def build_model(cls, cfg: Wav2Vec2CtcConfig, task: FairseqTask): # -> Self:
        """Build a new model instance."""
        ...
    
    def get_logits(self, net_output, normalize=...): # -> Tensor:
        ...
    
    def get_normalized_probs(self, net_output, log_probs): # -> Tensor:
        """Get normalized probabilities (or log probs) from a net's output."""
        ...
    
    def forward(self, **kwargs): # -> Any:
        ...
    


@dataclass
class Wav2Vec2Seq2SeqConfig(Wav2Vec2AsrConfig):
    decoder_embed_dim: int = ...
    decoder_ffn_embed_dim: int = ...
    decoder_layers: int = ...
    decoder_layerdrop: float = ...
    decoder_attention_heads: int = ...
    decoder_learned_pos: bool = ...
    decoder_normalize_before: bool = ...
    no_token_positional_embeddings: bool = ...
    decoder_dropout: float = ...
    decoder_attention_dropout: float = ...
    decoder_activation_dropout: float = ...
    max_target_positions: int = ...
    share_decoder_input_output_embed: bool = ...
    autoregressive: bool = ...


@register_model("wav2vec_seq2seq", dataclass=Wav2Vec2Seq2SeqConfig)
class Wav2Vec2Seq2SeqModel(FairseqEncoderDecoderModel):
    def __init__(self, encoder, decoder) -> None:
        ...
    
    @classmethod
    def build_model(cls, cfg: Wav2Vec2Seq2SeqConfig, task: FairseqTask): # -> BaseFairseqModel:
        """Build a new model instance."""
        ...
    
    @classmethod
    def build_encoder(cls, cfg: Wav2Vec2AsrConfig): # -> Wav2VecEncoder:
        ...
    
    @classmethod
    def build_decoder(cls, cfg: Wav2Vec2Seq2SeqConfig, tgt_dict, embed_tokens): # -> TransformerDecoder:
        ...
    
    def forward(self, **kwargs):
        ...
    
    def upgrade_state_dict_named(self, state_dict, name):
        ...
    


class Wav2VecEncoder(FairseqEncoder):
    def __init__(self, cfg: Wav2Vec2AsrConfig, output_size=...) -> None:
        ...
    
    def load_model_weights(self, state, model, cfg): # -> None:
        ...
    
    def set_num_updates(self, num_updates): # -> None:
        """Set the number of parameters updates."""
        ...
    
    def forward(self, source, padding_mask, **kwargs): # -> dict[str, Any]:
        ...
    
    def forward_torchscript(self, net_input): # -> dict[str, Any]:
        ...
    
    def reorder_encoder_out(self, encoder_out, new_order):
        ...
    
    def max_positions(self): # -> None:
        """Maximum input length supported by the encoder."""
        ...
    
    def upgrade_state_dict_named(self, state_dict, name):
        ...
    


class TransformerDecoder(FairseqIncrementalDecoder):
    """
    Transformer decoder consisting of *args.decoder_layers* layers. Each layer
    is a :class:`TransformerDecoderLayer`.

    Args:
        args (argparse.Namespace): parsed command-line arguments
        dictionary (~fairseq.data.Dictionary): decoding dictionary
        embed_tokens (torch.nn.Embedding): output embedding
        no_encoder_attn (bool, optional): whether to attend to encoder outputs
            (default: False).
    """
    def __init__(self, cfg: Wav2Vec2Seq2SeqConfig, dictionary, embed_tokens, no_encoder_attn=...) -> None:
        ...
    
    def forward(self, prev_output_tokens, encoder_out=..., incremental_state=..., **unused): # -> tuple[Tensor, dict[str, Any | list[Tensor] | None]]:
        """
        Args:
            prev_output_tokens (LongTensor): previous decoder outputs of shape
                `(batch, tgt_len)`, for teacher forcing
            encoder_out (Tensor, optional): output from the encoder, used for
                encoder-side attention
            incremental_state (dict): dictionary used for storing state during
                :ref:`Incremental decoding`

        Returns:
            tuple:
                - the decoder's output of shape `(batch, tgt_len, vocab)`
                - a dictionary with any model-specific outputs
        """
        ...
    
    def extract_features(self, prev_output_tokens, encoder_out=..., incremental_state=..., **unused): # -> tuple[Tensor | Any, dict[str, Any | list[Tensor] | None]]:
        """
        Similar to *forward* but only return features.

        Returns:
            tuple:
                - the decoder's features of shape `(batch, tgt_len, embed_dim)`
                - a dictionary with any model-specific outputs
        """
        ...
    
    def output_layer(self, features, **kwargs): # -> Tensor:
        """Project features to the vocabulary size."""
        ...
    
    def max_positions(self): # -> int:
        """Maximum output length supported by the decoder."""
        ...
    
    def buffered_future_mask(self, tensor): # -> Tensor:
        ...
    
    def upgrade_state_dict_named(self, state_dict, name):
        ...
    


def Embedding(num_embeddings, embedding_dim, padding_idx): # -> Embedding:
    ...

def Linear(in_features, out_features, bias=...): # -> Linear:
    ...

