"""
This type stub file was generated by pyright.
"""

import torch
from typing import Dict, List, Optional, Tuple
from fairseq.models import FairseqEncoder, FairseqEncoderDecoderModel, register_model, register_model_architecture
from fairseq.models.transformer import TransformerDecoder
from torch import Tensor

logger = ...
@register_model("convtransformer")
class ConvTransformerModel(FairseqEncoderDecoderModel):
    """
    Transformer-based Speech translation model from ESPNet-ST
    https://arxiv.org/abs/2004.10234
    """
    def __init__(self, encoder, decoder) -> None:
        ...
    
    @staticmethod
    def add_args(parser): # -> None:
        """Add model-specific arguments to the parser."""
        ...
    
    @classmethod
    def build_encoder(cls, args): # -> FairseqEncoder | FairseqDecoder | ConvTransformerEncoder:
        ...
    
    @classmethod
    def build_decoder(cls, args, task, embed_tokens): # -> FairseqEncoder | FairseqDecoder | TransformerDecoderNoExtra:
        ...
    
    @classmethod
    def build_model(cls, args, task): # -> Self:
        """Build a new model instance."""
        ...
    
    @staticmethod
    @torch.jit.unused
    def set_batch_first(lprobs): # -> None:
        ...
    
    def get_normalized_probs(self, net_output: Tuple[Tensor, Optional[Dict[str, List[Optional[Tensor]]]]], log_probs: bool, sample: Optional[Dict[str, Tensor]] = ...): # -> Any | Tensor:
        ...
    
    def output_layout(self): # -> Literal['BTD']:
        ...
    
    def forward(self, src_tokens, src_lengths, prev_output_tokens):
        ...
    


class ConvTransformerEncoder(FairseqEncoder):
    """Conv + Transformer encoder"""
    def __init__(self, args) -> None:
        """Construct an Encoder object."""
        ...
    
    def pooling_ratio(self): # -> Literal[4]:
        ...
    
    def infer_conv_output_dim(self, in_channels, input_dim, out_channels): # -> Any:
        ...
    
    def forward(self, src_tokens, src_lengths): # -> dict[str, list[Tensor | Any] | list[Any]]:
        """Encode input sequence.
        :param torch.Tensor xs: input tensor
        :param torch.Tensor masks: input mask
        :return: position embedded tensor and mask
        :rtype Tuple[torch.Tensor, torch.Tensor]:
        """
        ...
    
    @torch.jit.export
    def reorder_encoder_out(self, encoder_out: Dict[str, List[Tensor]], new_order): # -> dict[str, list[Tensor]]:
        """
        Reorder encoder output according to *new_order*.

        Args:
            encoder_out: output from the ``forward()`` method
            new_order (LongTensor): desired order

        Returns:
            *encoder_out* rearranged according to *new_order*
        """
        ...
    


class TransformerDecoderNoExtra(TransformerDecoder):
    def extract_features(self, prev_output_tokens, encoder_out: Optional[Dict[str, List[Tensor]]], incremental_state: Optional[Dict[str, Dict[str, Optional[Tensor]]]] = ..., full_context_alignment: bool = ..., alignment_layer: Optional[int] = ..., alignment_heads: Optional[int] = ...): # -> tuple[Any, None]:
        ...
    


@register_model_architecture(model_name="convtransformer", arch_name="convtransformer")
def base_architecture(args): # -> None:
    ...

@register_model_architecture("convtransformer", "convtransformer_espnet")
def convtransformer_espnet(args): # -> None:
    ...

