"""
This type stub file was generated by pyright.
"""

import torch.nn as nn

class PQEmbedding(nn.Module):
    """
    Quantized counterpart of nn.Embedding module. Stores the centroids and
    the assignments. The full weight is re-instantiated at each forward
    pass.

    Args:
        - centroids: centroids of size n_centroids x block_size
        - assignments: assignments of the centroids to the subvectors
          of size self.out_features x n_blocks
        - bias: the non-quantized bias

    Remarks:
        - We refer the reader to the official documentation of the nn.Embedding module
          for the other arguments and the behavior of the module
        - Performance tests on GPU show that this implementation is 10% slower than
          the non-quantized nn.Embedding module for a standard training loop.
    """
    def __init__(self, centroids, assignments, num_embeddings, embedding_dim, padding_idx=..., max_norm=..., norm_type=..., scale_grad_by_freq=..., sparse=..., _weight=...) -> None:
        ...
    
    @property
    def weight(self): # -> Tensor:
        ...
    
    def forward(self, input): # -> Tensor:
        ...
    
    def extra_repr(self): # -> str:
        ...
    


