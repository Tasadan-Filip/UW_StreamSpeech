"""
This type stub file was generated by pyright.
"""

import torch.nn as nn

class PQConv2d(nn.Module):
    """
    Quantized counterpart of nn.Conv2d module. Stores the centroid, the assignments
    and the non-quantized biases. The full weight is re-instantiated at each forward
    pass and autograd automatically computes the gradients with respect to the
    centroids.

    Args:
        - centroids: centroids of size n_centroids x block_size
        - assignments: assignments of the centroids to the subvectors
          of size self.out_channels x n_blocks
        - bias: the non-quantized bias, must be either torch.Tensor or None

    Remarks:
        - We refer the reader to the official documentation of the nn.Conv2d module
          for the other arguments and the behavior of the module.
        - Performance tests on GPU show that this implementation is 10% slower than
          the non-quantized nn.Conv2d module for a standard training loop.
        - During the backward, the gradients are averaged by cluster and not summed.
          This explains the hook registered to the centroids.
    """
    def __init__(self, centroids, assignments, bias, in_channels, out_channels, kernel_size, stride=..., padding=..., dilation=..., groups=..., padding_mode=...) -> None:
        ...
    
    @property
    def weight(self): # -> Tensor:
        ...
    
    def forward(self, x): # -> Tensor:
        ...
    
    def extra_repr(self): # -> str:
        ...
    


