"""
This type stub file was generated by pyright.
"""

import torch.nn as nn

class IntLinear(nn.Module):
    """
    Quantized counterpart of the nn.Linear module that applies QuantNoise during training.

    Args:
        - in_features: input features
        - out_features: output features
        - bias: bias or not
        - p: amount of noise to inject (0 = no quantization, 1 = quantize all the weights)
        - bits: number of bits
        - method: choose among {"tensor", "histogram", "channel"}
        - update_step: recompute scale and zero_point every update_steps iterations

    Remarks:
        - We use the straight-through estimator so that the gradients
          back-propagate nicely in the network, this is implemented with
          the detach() trick.
        - Parameters scale and zero_point are recomputed every update_step
          forward pass to reduce the overhead
        - At test time, the weights are fully quantized
    """
    def __init__(self, in_features, out_features, bias=..., p=..., update_step=..., bits=..., method=...) -> None:
        ...
    
    def reset_parameters(self): # -> None:
        ...
    
    def forward(self, input): # -> Tensor:
        ...
    
    def extra_repr(self): # -> str:
        ...
    


