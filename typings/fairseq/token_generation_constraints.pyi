"""
This type stub file was generated by pyright.
"""

import torch
from collections import Counter
from typing import List, Set

"""Implements tracking of constraints for a beam item.

A list of constraints is given as a list of one or more token
sequences, each of length at least one token. For example, for an input sentence

> Die maschinelle Ãœbersetzung ist schwer zu kontrollieren.

We could have the constraints:
* to influence
* hard

There are two implementations:
* OrderedConstraintState: Tracks progress through an ordered list of multitoken constraints.
* UnorderedConstraintState: Tracks progress through an unordered list of multitoken constraints.

The difference is that in the first, the constraints are assumed to be
in order; the algorithm will permit zero or more tokens between them.
In the second, the constraints are not ordered, so many orderings will
be explored.

The same sequence can be present any number of times, and will appear
that many times in the output.
"""
class ConstraintState:
    def __init__(self) -> None:
        ...
    


def pack_constraints(batch_constraints: List[List[torch.Tensor]]) -> torch.Tensor:
    """Takes a list of list of constraints in tensor form (a list of
    tensor constraints for each sentence) and transforms it into a
    packed Tensor. For example, here is a batch of size 3 with 3, 0,
    and 1 constraints:

        [ [ [3 1 2], [3], [4 5 6 7], ]
          [],
          [ [1 8 9 10 1 4 11 12], ]
        ]

    Its corresponding packed structure is:

        [ [ 3  3  1  2  0  3  0  4  5  6  7  0],
          [ 0  0  0  0  0  0  0  0  0  0  0  0],
          [ 1  1  8  9 10  1  4 11 12  0  0  0] ]

    The packed tensor has shape (batch size, maxlen), where
    maxlen is defined below. Each row contains concatenated
    constraint tokens for that sentence, with 0 appended after
    each constraint. The first item in each row is the number
    of constraints for that sentence. So maxlen is the maximum
    of

    (number of constraints) + (sum length of constraints) + 1.

    across all sentences in the batch.
    """
    ...

def unpack_constraints(constraint_tensor: torch.Tensor) -> List[torch.Tensor]:
    """
    Transforms *one row* of a packed constraint tensor (e.g., for one
    sentence in the batch) into a list of constraint tensors.
    """
    ...

class ConstraintNode:
    """
    Represents a node in a trie managing unordered constraints.
    """
    def __init__(self, token: int = ..., parent=...) -> None:
        ...
    
    @property
    def id(self): # -> int | None:
        ...
    
    def __str__(self) -> str:
        ...
    
    def __getitem__(self, key: int):
        ...
    
    def next_tokens(self) -> Set[int]:
        """The set of child labels."""
        ...
    
    @staticmethod
    def create(constraints: List[List[int]]): # -> ConstraintNode:
        ...
    
    @staticmethod
    def print_graph(node: ConstraintNode): # -> str:
        ...
    
    def token_counts(self) -> Counter:
        """Returns a counter of the number of times each token is used
        in a constraint.
        """
        ...
    
    def tokens(self) -> Set[int]:
        """Returns the set of tokens in constraints."""
        ...
    
    def add_sequence(self, sequence: List[int]): # -> None:
        """Adds a constraint, represented as a list of integers, to
        the trie."""
        ...
    


class UnorderedConstraintState(ConstraintState):
    """
    Records progress through the set of constraints for each item in the beam
    using a trie.
    """
    def __init__(self, node: ConstraintNode, copy_from: ConstraintState = ...) -> None:
        ...
    
    @staticmethod
    def create(constraint_tensor: torch.Tensor): # -> UnorderedConstraintState:
        ...
    
    def __str__(self) -> str:
        ...
    
    def __copy__(self): # -> UnorderedConstraintState:
        ...
    
    def copy(self): # -> UnorderedConstraintState:
        ...
    
    @property
    def name(self): # -> str:
        ...
    
    @property
    def is_root(self): # -> bool:
        ...
    
    @property
    def bank(self): # -> int:
        ...
    
    @property
    def num_completed(self): # -> int:
        """The number of constraints (not constraint tokens) that are completed.
        In addition to the already-completed states, we need to account for the
        current state, which might get marked as completed when another token
        is generated.
        """
        ...
    
    @property
    def finished(self): # -> bool:
        ...
    
    @property
    def token_counts(self): # -> Counter[Any]:
        ...
    
    @property
    def tokens(self): # -> Set[int]:
        ...
    
    @property
    def num_constraint_tokens(self): # -> int:
        ...
    
    def next_tokens(self) -> Set[int]:
        """Returns the list of tokens that could come next.
        These are (a) all tokens extending the root state and, for
        non-root states, additionally all tokens extending the current
        state."""
        ...
    
    def advance(self, token: int): # -> UnorderedConstraintState:
        """Reads in a token and advances the state. Here's how it works.

        We can advance to the next state if:
        - there is a matching child
        - its path isn't blocked

        A path is blocked when all constraints that are descendants of
        that node have already been generated, in the current state.

        If we are not able to advance from the current state, we "fall
        off the graph" and return to the root state. There, we again
        try to advance, checking the same criteria.

        In any case, when falling off the graph, we need to do some
        bookkeeping. We:
        - check whether any constraints were met (all prefixes of
          current state)
        - if one is found, mark it as completed
        - adjust visited nodes accordingly
        """
        ...
    


class ConstraintSequence:
    def __init__(self, sequences: List[List[int]]) -> None:
        """Represents a set of possibly multitoken constraints by
        concatenating them and internally recording the end points.
        """
        ...
    
    def __getitem__(self, key: int):
        ...
    
    def __len__(self): # -> int:
        ...
    
    def __str__(self) -> str:
        ...
    


class OrderedConstraintState(ConstraintState):
    """
    Records progress through the set of linear nonbranching constraints with gaps.
    """
    def __init__(self, sequence: ConstraintSequence, state: int = ...) -> None:
        ...
    
    @staticmethod
    def create(constraint_tensor: torch.Tensor): # -> OrderedConstraintState:
        ...
    
    def __str__(self) -> str:
        ...
    
    def __copy__(self): # -> OrderedConstraintState:
        ...
    
    def copy(self): # -> OrderedConstraintState:
        ...
    
    @property
    def num_completed(self): # -> int:
        ...
    
    @property
    def is_root(self): # -> bool:
        ...
    
    @property
    def name(self): # -> str:
        ...
    
    @property
    def bank(self) -> int:
        ...
    
    @property
    def finished(self): # -> bool:
        ...
    
    @property
    def token_counts(self):
        ...
    
    @property
    def tokens(self): # -> set[Any]:
        ...
    
    @property
    def num_constraint_tokens(self): # -> int:
        ...
    
    def next_tokens(self) -> Set[int]:
        """Returns the list of tokens that could come next.
        These are (a) all tokens extending the root state and, for
        non-root states, additionally all tokens extending the current
        state."""
        ...
    
    def advance(self, token: int): # -> OrderedConstraintState:
        """Reads in a token and advances the state. Here's how it works.

        We can advance to the next state if:
        - there is a matching child
        - its path isn't blocked

        A path is blocked when all constraints that are descendants of
        that node have already been generated, in the current state.

        If we are not able to advance from the current state, we "fall
        off the graph" and return to the root state. There, we again
        try to advance, checking the same criteria.

        In any case, when falling off the graph, we need to do some
        bookkeeping. We:
        - check whether any constraints were met (all prefixes of
          current state)
        - if one is found, mark it as completed
        - adjust visited nodes accordingly
        """
        ...
    


