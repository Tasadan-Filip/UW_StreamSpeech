"""
This type stub file was generated by pyright.
"""

from dataclasses import dataclass
from typing import Optional
from fairseq.criterions import FairseqCriterion, register_criterion
from fairseq.data.data_utils import post_process
from fairseq.dataclass import FairseqDataclass
from fairseq.tasks import FairseqTask

@dataclass
class CtcCriterionConfig(FairseqDataclass):
    zero_infinity: bool = ...
    sentence_avg: bool = ...
    post_process: str = ...
    wer_kenlm_model: Optional[str] = ...
    wer_lexicon: Optional[str] = ...
    wer_lm_weight: float = ...
    wer_word_score: float = ...
    wer_args: Optional[str] = ...


@register_criterion("ctc", dataclass=CtcCriterionConfig)
class CtcCriterion(FairseqCriterion):
    def __init__(self, cfg: CtcCriterionConfig, task: FairseqTask, rdrop_alpha: int = ...) -> None:
        ...
    
    def forward(self, model, sample, reduce=..., **kwargs): # -> tuple[Tensor, Any, dict[str, Number | Tensor | Any]]:
        ...
    
    @staticmethod
    def reduce_metrics(logging_outputs) -> None:
        """Aggregate logging outputs from data parallel training."""
        ...
    
    @staticmethod
    def logging_outputs_can_be_summed() -> bool:
        """
        Whether the logging outputs returned by `forward` can be summed
        across workers prior to calling `reduce_metrics`. Setting this
        to True will improves distributed training speed.
        """
        ...
    


